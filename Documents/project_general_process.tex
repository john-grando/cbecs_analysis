\subsection{General Process}

Due to the large number of features in the survey responses, it is not possible to analyze each one individually.  Therefore, the first steps in the process will be centered around selecting a smaller subset.  A few algorithms will be used in order to try and reduce bias.  First, a principle component analysis will be performed.  Second, a partial least squares model will be fit to the response.  Third, a random forest regression will be used in order to try and extract any nonlinear relationships.  Fourth, an attempt to construct a lasso regression model will be made.  Fifth, a forward selection linear model will also be fit in order to see if an automated approach can be taken.  Finally, a simple neural network model will be trained to gauge the possible effectiveness of using this model type.  The magnitude and contribution percentage of each variable will be considered in selecting features from this model.  Also, the various error rates from each preliminary model will be used as a benchmark for the final model performance.

After the prelminary set of models have been run and summarized, the extracted variables will be analyzed in order to verify their importance, gauge their potential predictive power, and to check whether they are easily attainable for a building operator/owner.  This step is very important because it is essential worthwhile variables are used to predict the outcome.  Selecting a variable that, for one reason or another, is erroneous may lead to reduced predictive power in the final model.  If a variable did pass our initial analysis but doesn't actually have much predictive power (i.e. it only changes values by a slight amount) then it may not be worthwhile to select it at all.  All selected variables increase the complexity of the model; therefore, we wish to only select those that will matter.  Finally, the predictor must be usable, and 'knowable'.  Ultimately, this tool will not be usable if a very difficult and hard to understand, and/or attain, variable value is used.  These three concepts will be used in the analyzation of the candidate variables from the the preliminary analysis. 

Finally, a neural network model will be built to take the verified subset of features and make predictions for the selected major fuel use.  A variety of hyperparameters will be tested, using cross-validation, and compared on a common error metric.  This step will reveal the optimal hyperparameter combination to use for the model.  The prospective model will then be retrained on the entired entire training and validation data.  This model's selected error metrics will then be compared to the preliminary models, which should be considered a floor for performance.  Once this is done, the model can then be re-assessed for feature selection as well as analyzed for the value/tradeoff of adding/removing certain features.  

For each fuel end-use, two parrallel final models will be considered; one model will use a total consumption response variable in units of mmBTU, and another model that will be considered will have the response variable be normailzed based on gross floor area in units of BTU per square foot.  The final decision on which model will be chosen will come after the neural network models have been fully trained.