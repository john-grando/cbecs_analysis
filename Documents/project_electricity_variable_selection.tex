\section*{Electricity}
\label{sec:electricity}
\addcontentsline{toc}{section}{\nameref{sec:electricity}}

\subsection{General}

The preprocessed data was passed to the following process in order to determine the best possible set of candidate predictors with one additional filter.  Only buildings that indicated electricity being used \lstinline{ELUSED} were included in the samples for this major fuel use.  Then, one of each pair of predictors with correlations above 0.75 were removed, to avoid model selection issues. Additionally, the other major fuel consumption values were removed from the set of possible predictors since separate models will be made to predict these values as well.  Also, the numeric predictors were transformed via BoxCox methodology as well as centered and scaled due to the varying scales and skewness.

\subsection{\hyperref[appendix:electricity:response]{Response Analysis}}

The response data appear to be unimodal and have a heavy right skew with a median of 39.0, mean of 57.9, and max of 971.9 BTU/SF.  After filtering for this model's end-use, there are 6500 samples in the data set.  The log of the response was taken in an attempt to maintain homoscadicity as the variance of the energy used also scales with the magnitude.

\subsection{\hyperref[appendix:electricity:pca]{Variable Selection - PCA}}

The principle component analysis indicates that only 4.6\% of the variance in the data can be explained in the first principle component, which then drops to 1.7\% for the second principle component.  These results reveal that there does not appear to be clear axes that can explain the variance of the data very well, which indicates there may be some very complex interactions taking place in the predictors.

\begin{myitemize}
\item Variables Selected - \lstinline{COOK[NO]}, \lstinline{LAUNDR[NA]}
\item RMSE - NA
\item Rsquared - NA
\end{myitemize}

\subsection{\hyperref[appendix:electricity:pls]{Variable Selection - PLS}}

This model returned a promising result with an Rsquared value of 0.868; however, it must be noted that all predictors were used in this process.  Looking at the result, it is obvious that the use of refrigeration equipment is dominating the variable importance plot (RFG prefix) as well as some other seemingly reasonable predictors, such as the number of registers within the building.  

\begin{myitemize}
\item Variables Selected - \lstinline{RFGWinPerSf}, \lstinline{RGSTRNPerSf}, \lstinline{RFGICNPerSf}, \lstinline{FDSEATPerSF}, \lstinline{RFGCLNPerSf}, \lstinline{NWKERPerSf}, \lstinline{RFGOPNPerSf}
\item RMSE - 33988268
\item Rsquared - 0.8677
\end{myitemize}

\subsection{\hyperref[appendix:electricity:rf]{Variable Selection - Random Forest}}

As with the PLS, model, the resulting error metrics were promising, with slightly better RMSE and Rsquared values.  The selected variables are ver similar with a few exceptions.  This model has placed higher importance on a yes/no response to the presence of walk in refrigerators as well as whether or not a building is a fast food establishment

\begin{myitemize}
\item Variables Selected - \lstinline{RFGWinPerSf}, \lstinline{RGSTRNPerSf}, \lstinline{NWKERPerSf}, \lstinline{RFGWI[YES]}, \lstinline{RFGICNPerSf}, \lstinline{FDSEATPerSf}, \lstinline{PBAPLUS.32[Fast Food]}
\item RMSE - 52.33
\item Rsquared - 0.4729
\end{myitemize}

\subsection{\hyperref[appendix:electricity:l]{Variable Selection - Lasso}}
TBD

\subsection{\hyperref[appendix:electricity:lp]{Variable Selection - Forward Selection}}
TBD

\subsection{\hyperref[appendix:electricity:snn]{Variable Selection - Simple Neural Network}}
TBD

\subsection{\hyperref[appendix:electricity:rfe]{Variable Selection - Recursive Feature Elimination}}
TBD

\subsection{\hyperref[appendix:electricity:sv]{Variable Selection - Selected Variable Analysis}}
TBD - Take top 20 from each previous analysis, many will overlap.
