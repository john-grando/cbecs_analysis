\subsection{Data Pre-Processing}

The raw data set consists of 6,720 records and 1,119 features based on a stratified sample of commercial buildings.  Multiple steps of preprocessing were required in order to prepare the data.  Note, there are many columns which are being used as imputation flags and statistical weights (for aggregation) which, when removed, reduced the number of features down to approximately 400.  While these columns are useful to indicate where values have been imputed into the dataset by the source's own methodologies, rather than try to change back the data to the original records it has been determined that the imputed values were sufficiently applied and the dataset will not be imputed any further.

After evaluating the reduced data set, some feature engineering efforts were taken.  First, very specific cases which resulted in many null responses (e.g. buildings less than 1,000 gross square feet, buildings open for less than a year, etc.) were removed.  Second, some null entries were converted to zero when logically appropriate.  For example, if a building was indicated to not be cooled, then a follow up question asking what percentage of the building is cooled was not asked, resulting in an null.  In this instance, the null value was replaced with a zero.  Third, some values were removed as they simply did not apply to the study (e.g. expenditure for energy sources in USD).  Fourth, nominal categorical values that had null responses were encoded to a special value.  The logic for this approach is that if a null value for a feature ends up being a significant predictor, then it can be analzyed what factors make this situation occur.  Fifth, the categorical features were then one-hot encoded to separate columns.  The preprocessed data set was transformed to 6661 rows and 456 features (before one-hot encoding).