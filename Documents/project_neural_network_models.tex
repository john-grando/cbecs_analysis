
\section{Neural Network Models}
\label{sec:nn_models}
%\addcontentsline{toc}{section}{\nameref{sec:nn_models}}

\subsection{General}
The choice to use neural networks for the final model was multi-faceted.  First, these types of models are very good at capturing complex non-linear interactions.  This appears to be the case with the data set given the failure of lasso models as well as the low percentage of variance capture for the first few dimensions of the principal component and partial least squares analyses.  Secondly, neural networks have the ability to select different loss functions.  This is beneficial because it is important to highlight practicality of the results returned.  As the estimated energy consumption grows, it is somewhat acceptable for the error rate to grow proportionally if it results in better fits for the low estimates.  As an example, a large datacenter may use a lot of energy so a slightly higher absolute error rate may may be acceptable since it could be a small relative error compared to the overall consumption; conversely, if a non-heated warehouse, which uses very little energy, would be wildly innacurate with a similar absolute error rate.  Therefore, importance should be placed on minimizing the relative error rates.  To reflect this reasoning, the loss function for this set of models was chosen to be the mean absolute percentage error (MAPE).

\subsection{Hyperparameter Training}
In order to select the most optimized set of parameters, some hyperparameter training was performed.  Some standard searches were made, such as varying the dropout rate, regularization, learning rate, and batch size; however, one additional training set was incorporated to highlight the goals of this study.  A series of models were tested which had an incrementally decreasing number of variables, by least importance, in order to test the loss of accuracy.

\subsection{Electricity}
\subsubsection{Summary}
The final selected model consisted of a 3 hidden layers, 200 hidden layer nodes, a dropout rate of 0.6, no regularization, batch sizes of 150, using the rmsprop() algorithm with a learning rate of 0.001, and 100 predictors.  As can be seen in the graph below, the number of variables needed to obtain near-peak performance, is much less than the full set.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth, height=0.25\textheight]{Images/electricity_psf_nn_error.png}
\end{figure}

The final selected model, after re-training, has a MSLE of 0.875 and RMSE of 15357.  Comparing this model ('Full Neural Network') to the previous feature extraction models, which used many more variables, the performance is competitive.  Additionally, the results were then multiplied by their respect gross floor area and then compared to the set of feature extraction models, with the same transformation, in order to evaluate the total consumption prediction error.  Again, it can be seen that this neural network model has shown to be competetive in this manner and, in fact, has a better Rsquared value.

The resdiuals indicate that the variance scales with the response variable; however, since neural network models do not operate on a principle of homoscedacitity, only underlying patterns are of concern. Additionally, the noted error pattern is by design since the loss function (MAPE) allows for higher error in higher consumption projects.  \textit{\hyperref[appendix_nn:electricity:nn_full]{Appendix}}

\begin{figure}[h]
\centering
\includegraphics[width=.49\textwidth, height=0.25\textheight]{Images/electricity_psf_model_summary.png}
\includegraphics[width=0.49\textwidth, height=0.25\textheight]{Images/electricity_psf_model_summary_transformed.png}
\end{figure}


\subsubsection{Variable Selection Summary}
The final model chosen uses 100 variables.  Many of the features within the set have to do with the amount of receptacle equipment within the building as well as major electrical devices (e.g. MRI machines) and essential equipment (e.g. data center servers, refrigeration).  Also, building type identifiers have been included for various categories. \textit{\hyperref[appendix_nn:electricity:nn_full_variables]{Appendix}}

The automated selection process does seem to have included some highly correlated pairs, such as the number of workers per square foot as well as the categorical bin of workers.  This does reduce the number of necessary questions, but it is unclear if both are necessary and/or if they are possibly detrimental.  Also, there are a number of questions that may be automatically known just based on the usage type as some questions do not apply to all buidlings.  It is possible take the steps used in asking questions in the survey in order to build a live form that can automatically parse out the meaningful questions based on building type, which could reduce the need to enter a value for all the selected variables.

%\FloatBarrier
%\newpage
\subsection{Natural Gas}
\subsubsection{Summary}
The final selected model consisted of a 4 hidden layers, 400 hidden layer nodes, a dropout rate of 0.9, no regularization, batch sizes of 50, using the rmsprop() algorithm with a learning rate of 0.001, and 100 predictors.  As can be seen in the graph below, the number of variables needed to obtain near-peak performance, is much less than the full set.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth, height=0.25\textheight]{Images/natural_gas_psf_nn_error.png}
\end{figure}

\subsubsection{Variable Selection Summary}
The final selected model, after re-training, has a MSLE of 0.875 and RMSE of 58528.  Comparing this model ('Full Neural Network') to the previous feature extraction models, which used many more variables, the performance is actually better.  Additionally, the results were then multiplied by their respect gross floor area and then compared to a set of feature extraction models that were trained on total consumption.  Again, it can be seen that this neural network model is the best performing out of the set and has a better Rsquared value than the per SF model.  Much like the electricity data set, there appears to be heteroscedacicity in the residuals, but may be due to the selected loss function.

\begin{figure}[h]
\centering
\includegraphics[width=.49\textwidth, height=0.25\textheight]{Images/natural_gas_psf_model_summary.png}
\includegraphics[width=0.49\textwidth, height=0.25\textheight]{Images/natural_gas_psf_model_summary_transformed.png}
\end{figure}

\subsection{Future Work}
While it was determined that some heteroscedacitity would be acceptable, there does appear to be area for improvement.  Additionally, as mentioned at the beginning of this report, the sampling of this data set was stratified to reflect the building population.  However, it is noted that there are some building classes that have greater variance than others.  Therefore, it may be useful to use this stratification as a weighted method, based on \lstinline{PBAPLUS}, in order to try and emphasize accuracy on the most prevalent budiding types. Also, there was not a lot of attention paid to the actual transformations of the predictors given the large quantity of them.  It is possible a better fit can be obtained with more intelligent transformations applied to the features after further analysis.  Finally, the neural network model was trained on the original (untransformed) response variable, rather than taking the log transformation, as was done in some of the feature extraction models.  This was done because it was assumed that the neural network would pick up on the skewness of the data without further preprocessing.  Also, testing transformations on the response would result in further hyperparameter training which could not be done due to time constraints.  It is possible a better fit could be obtained by experimenting with further transformations of the response.

%\FloatBarrier
%\newpage
%\subsection{District Heat}

%\FloatBarrier
%\newpage
%\subsection{Fuel Oil}